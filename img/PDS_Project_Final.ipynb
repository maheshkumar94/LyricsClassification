{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15688 Final Project: Genre classification of songs using lyrics text analysis\n",
    "\n",
    "###  Submitted by   Keerthy Muralidharan,  Mahesh Kumar Srinivas and Priyadarshini Mitra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/MUSIC.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Music Classification is a fairly common topic, and there are many ways to classify songs on features like danceability, energy, tempo, etc. Indeed, classifying songs on these features is so commonplace that commercial music streaming services like Spotify provide an off the shelf solution to retrieve these audio features, and others like\n",
    "\n",
    "1. Danceability\n",
    "2. Energy\n",
    "3. Loudness\n",
    "4. Speechiness\n",
    "5. Acousticness\n",
    "6. Tempo\n",
    "\n",
    "These are audio features that are readily available for use through the Spotify API.\n",
    "\n",
    "We differentiate our classification by one fundamental change - Lyrics. Every genre has several issues/subjects that it tackles. By identifying these topics as most frequently occurring words, we're able to accurately classify songs that deal with similar topics and contain similar words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "In order to work with the lyrics _and_ the genre of the songs, we had to combine data from a variety of sources. No existing dataset contained all the information for us to work with.\n",
    "\n",
    "These are our primary sources of the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listed below is our approach to this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Million Song Dataset (LabROSA)\n",
    "\n",
    "In order to get the actual songs to be used, we used the million song dataset, which is a freely-available collection of audio features and metadata for a million contemporary popular music tracks.\n",
    "\n",
    "The artist and track information for a million unique tracks are available, and were used to fetch more data, namely their Genre and Lyrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LyricWiki\n",
    "\n",
    "LyricWiki (lyrics.wikia.com) is an online wiki-based lyrics database and encyclopaedia. The lyrics on LyricWiki are all licensed through LyricFind.\n",
    "\n",
    "We use the artist and the track to retreive lyrics. All songs on LyricsWiki follow the same URL pattern:\n",
    "\n",
    "http://lyrics.wikia.com/wiki/Opeth:Blackwater_Park (Opeth is the Artist Name, and Blackwater Park is the song name.)\n",
    "\n",
    "Using standard web scraping through BeautifulSoup, we're able to extract the lyrics of the songs. In order to ensure we retrieve only songs in English, a meta tag is checked for the language of the song.\n",
    "\n",
    "Any songs with no lyrics, or non-english lyrics are removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_lyrics(file):\n",
    "    song_df = pd.read_csv(file)\n",
    "    song_dict={}\n",
    "    for i in range(len(song_df)):\n",
    "        songunique = str(song_df.iloc[i]['Artist'])+\",\"+str(song_df.iloc[i]['Song'])\n",
    "        flag=True\n",
    "        print(songunique)\n",
    "        for x in range(len(songunique)):\n",
    "            if ord(songunique[x])>=128:\n",
    "                flag=False\n",
    "        if flag==True:\n",
    "            try:\n",
    "                #This is the url constructed given the artist and track name\n",
    "                url = \"http://lyrics.wikia.com/wiki/\"+song_df.iloc[i]['Artist'].replace(\" \",\"_\")+\":\"+song_df.iloc[i]['Song'].replace(\" \",\"_\")\n",
    "                resp = urllib.request.urlopen(url)\n",
    "                root = BeautifulSoup(resp.read(),\"html.parser\")\n",
    "                meta = root.find(\"meta\", attrs={\"name\":\"keywords\"})\n",
    "                if \"English\" in str(meta):\n",
    "                    lyr = root.find(\"div\", class_=\"lyricbox\")\n",
    "                    string = str(lyr).replace(\"<br/>\",\" \")[22:-38]\n",
    "                else:\n",
    "                    string = \"null\"\n",
    "            except urllib.error.HTTPError as err:\n",
    "                if err.code!=200:\n",
    "                    string = \"null\"\n",
    "                else:\n",
    "                    raise\n",
    "        else:\n",
    "            string=\"null\"\n",
    "        song_dict[songunique]=string\n",
    "\n",
    "\n",
    "    lyr_dict = {}\n",
    "    for k,v in song_dict.items():\n",
    "        if v != \"null\":\n",
    "            lyr_dict[k]=v\n",
    "            \n",
    "    lyr_df = pd.DataFrame(list(lyr_dict.items()), columns = ['Song', 'Lyrics'])\n",
    "    \n",
    "    return lyr_df    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Last.fm API\n",
    "\n",
    "Last.fm is a website that \"scrobbles\" or identifies and records the songs that users listen to. It has information about millions of songs, like Artist, Album, Genre, Release Date, etc. These tags are all community contributed.\n",
    "\n",
    "Using calls to the Last.fm API, we retrieve the tag level information of songs, as a JSON object. This object is parsed to identify the genre of all the songs in the dataset.\n",
    "\n",
    "The resultant dataframe is further cleaned, by clubbing together similar genres. E.g., Progressive Metal, Death Metal, Heavy Metal, and other subgenres of metal are clubbed into a single Metal genre. A similar process is used for other genres like rap and hip-hop, dance, disco, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_genres(df, api_key):\n",
    "    genreList=[]\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        urlString = \"http://ws.audioscrobbler.com/2.0/?method=track.getInfo&api_key=\"+api_key\n",
    "        artist = df.iloc[i]['Artist']\n",
    "        track = df.iloc[i]['Song']\n",
    "        print(i, artist, track)\n",
    "        urlString+=\"&artist=\"+artist.lower()+\"&track=\"+track.lower()+\"&format=json\"\n",
    "        response = requests.get(urlString).json()\n",
    "        try:\n",
    "            genre = response['track']['toptags']['tag'][0]['name']\n",
    "        except (IndexError,KeyError,ValueError,ConnectionError):\n",
    "            genre = \"null\"\n",
    "        genreList.append(genre)\n",
    "        \n",
    "    df['Genre']=pd.Series(genreList)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the genre information extracted from Last.fm, we are further cleaning the data, by removing all null genres, and any genre that hasn't occurred atleast 30 times in the dataset.\n",
    "\n",
    "We are further clubbing together subgenres into their parent genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_nulls():\n",
    "    lyrics_df=lyrics_df[ lyrics_df['Genre'] != \"null\" ] \n",
    "    lyrics_df.reset_index()\n",
    "    lyrics_counter=dict(Counter(lyrics_df['Genre']))\n",
    "    genres=[k for k in lyrics_counter.keys() if lyrics_counter[k]>30]\n",
    "\n",
    "    lyrics_genre_df = lyrics_df[ lyrics_df['Genre'].isin(genres)]\n",
    "    lyrics_genre_df.to_csv(\"genre_clean2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def club_genres(df):\n",
    "    gen_parent = []\n",
    "    for i in range(len(df)):\n",
    "        genre = df.iloc[i]['Genre']\n",
    "        if \"metal\" in genre.lower() or \"industrial\" in genre.lower() or \"hardcore\" in genre.lower() :\n",
    "            #Clubbing together all metal subgenres\n",
    "            gen_parent.append('Metal')\n",
    "        elif \"rock\" in genre.lower() or \"grunge\" in genre.lower():\n",
    "            #Clubbing together all rock subgenres\n",
    "            gen_parent.append('Rock')\n",
    "        elif \"hop\" in genre.lower() or \"rap\" in genre.lower():\n",
    "            #Clubbing together rap and hip-hop\n",
    "            gen_parent.append(\"Hip Hop\")\n",
    "        elif \"pop\" in genre.lower():\n",
    "            #Clubbing together all pop subgenres\n",
    "            gen_parent.append('Pop')\n",
    "        elif \"punk\" in genre.lower():\n",
    "            #Clubbing together all punk subgenres\n",
    "            gen_parent.append(\"Punk\")\n",
    "        elif \"disco\" in genre.lower() or \"dance\" in genre.lower() or \"trance\" in genre.lower():\n",
    "            #Clubbing together all dance and disco music\n",
    "            gen_parent.append(\"Dance/Disco\")\n",
    "        elif \"christ\" in genre.lower():\n",
    "            #Clubbing together all christian and christmas music\n",
    "            gen_parent.append(\"Christian\")\n",
    "        else:\n",
    "            gen_parent.append(genre)\n",
    "\n",
    "    df['Genre'] = pd.Series(gen_parent)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data was scraped we cleansed the data using the following modules. We removed 'nulls' we had appended in the dataframe. Filtered the dataframe based on genre and took only those genres that were present more than 1000 times.We removed numbers, special characters, common words like \"Verse\", \"Version\", \"Chorus\" from Songs and Lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import string\n",
    "from collections import Counter\n",
    "import gensim\n",
    "import sklearn.manifold\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import OrderedDict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics as mt\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import multiprocessing\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['indie', 'country', 'pop', 'rock', 'metal']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Song</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Genre</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear Reader</td>\n",
       "      <td>Dearheart</td>\n",
       "      <td>I never wrote a love song That didn't go 'woe ...</td>\n",
       "      <td>indie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tammy Wynette</td>\n",
       "      <td>D-I-V-O-R-C-E</td>\n",
       "      <td>Our little boy is four years old and quite a l...</td>\n",
       "      <td>country</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheryl Cole</td>\n",
       "      <td>Fight For This Love</td>\n",
       "      <td>Too much of anything can make you sick Even th...</td>\n",
       "      <td>pop</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sugar Ray</td>\n",
       "      <td>Burning Dog</td>\n",
       "      <td>Look around help me out Breaking up breaking d...</td>\n",
       "      <td>rock</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chely Wright</td>\n",
       "      <td>Broken</td>\n",
       "      <td>Why can't you just believe in me? Not everyone...</td>\n",
       "      <td>country</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Artist                 Song  \\\n",
       "0    Dear Reader            Dearheart   \n",
       "1  Tammy Wynette        D-I-V-O-R-C-E   \n",
       "2    Cheryl Cole  Fight For This Love   \n",
       "3      Sugar Ray          Burning Dog   \n",
       "4   Chely Wright               Broken   \n",
       "\n",
       "                                              Lyrics    Genre  labels  \n",
       "0  I never wrote a love song That didn't go 'woe ...    indie       0  \n",
       "1  Our little boy is four years old and quite a l...  country       1  \n",
       "2  Too much of anything can make you sick Even th...      pop       2  \n",
       "3  Look around help me out Breaking up breaking d...     rock       3  \n",
       "4  Why can't you just believe in me? Not everyone...  country       1  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_clean_labels=pd.read_csv(\"lyrics_final_data.csv\",encoding = 'utf8')\n",
    "genre_clean_labels = genre_clean_labels[genre_clean_labels['Genre']!='null']\n",
    "genre_clean_labels['Genre'] = genre_clean_labels['Genre'].str.lower()\n",
    "\n",
    "genre_counter=dict(Counter(genre_clean_labels['Genre']))\n",
    "genres_1=[k for k in genre_counter.keys() if genre_counter[k]>1000]\n",
    "print(genres_1)\n",
    "\n",
    "genre_clean_labels = genre_clean_labels[genre_clean_labels['Genre'].isin(genres_1)]\n",
    "\n",
    "genre_clean_labels= genre_clean_labels[genre_clean_labels['Genre']!='female vocalists']\n",
    "\n",
    "genre_clean_labels.reset_index(drop=True)\n",
    "\n",
    "df=genre_clean_labels\n",
    "\n",
    "df.groupby('Genre').count()\n",
    "\n",
    "data=df\n",
    "\n",
    "genres=list(df['Genre'].unique())\n",
    "\n",
    "genres = [x.lower() for x in genres]\n",
    " \n",
    "genre_label=[]\n",
    "\n",
    "for row in df.iterrows(): \n",
    "    gen = getattr(row[1], 'Genre')\n",
    "    genre_label.append(genres.index(gen.lower()))\n",
    "\n",
    "class_lab = np.asarray(genre_label)\n",
    " \n",
    "data['labels']=class_lab\n",
    "data = data.reset_index(drop=True)\n",
    "len(data['labels'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Song</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Genre</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear Reader</td>\n",
       "      <td>Dearheart</td>\n",
       "      <td>I never wrote a love song That didn t go  woe ...</td>\n",
       "      <td>indie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tammy Wynette</td>\n",
       "      <td>D I V O R C E</td>\n",
       "      <td>Our little boy is four years old and quite a l...</td>\n",
       "      <td>country</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheryl Cole</td>\n",
       "      <td>Fight For This Love</td>\n",
       "      <td>Too much of anything can make you sick Even th...</td>\n",
       "      <td>pop</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sugar Ray</td>\n",
       "      <td>Burning Dog</td>\n",
       "      <td>Look around help me out Breaking up breaking d...</td>\n",
       "      <td>rock</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chely Wright</td>\n",
       "      <td>Broken</td>\n",
       "      <td>Why can t you just believe in me  Not everyone...</td>\n",
       "      <td>country</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Artist                 Song  \\\n",
       "0    Dear Reader            Dearheart   \n",
       "1  Tammy Wynette        D I V O R C E   \n",
       "2    Cheryl Cole  Fight For This Love   \n",
       "3      Sugar Ray          Burning Dog   \n",
       "4   Chely Wright               Broken   \n",
       "\n",
       "                                              Lyrics    Genre  labels  \n",
       "0  I never wrote a love song That didn t go  woe ...    indie       0  \n",
       "1  Our little boy is four years old and quite a l...  country       1  \n",
       "2  Too much of anything can make you sick Even th...      pop       2  \n",
       "3  Look around help me out Breaking up breaking d...     rock       3  \n",
       "4  Why can t you just believe in me  Not everyone...  country       1  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_noise(text):    \n",
    "    proc = re.sub(r'\\(.*?\\)','',text)\n",
    "    proc = re.sub(r'\\[.*?\\]','',text)\n",
    "    proc = re.sub(r'\\,.*?,',' ',text)\n",
    "    proc = re.sub(r'\\'|\\?',' ',text)\n",
    "    proc = re.sub(r'[V|v]erse','',text)\n",
    "    proc = re.sub(r'[v|V]ersion','',text)\n",
    "    proc = re.sub(r'[c|C]horus','',text)\n",
    "    \n",
    "    return proc\n",
    "\n",
    "\n",
    "\n",
    "data['Lyrics']=data['Lyrics'].apply(remove_noise)\n",
    "data['Lyrics']=data['Lyrics'].str.replace('[^\\w\\s]',' ')\n",
    "data['Song']=data['Song'].apply(remove_noise)\n",
    "data['Song'] = data['Song'].str.replace('[^\\w\\s]',' ')\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us see an over view of our data set. Below are the visualizations of number of songs per genre and number of artists per song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Songs_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country</td>\n",
       "      <td>1261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indie</td>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>metal</td>\n",
       "      <td>1943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pop</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rock</td>\n",
       "      <td>4344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Genre  Songs_Count\n",
       "0  country         1261\n",
       "1    indie         1746\n",
       "2    metal         1943\n",
       "3      pop         2002\n",
       "4     rock         4344"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data\n",
    "songs_count_df = df[['Song','Genre']].groupby(['Genre']).agg({'Song':'count'})\n",
    "\n",
    "songs_count_df.rename(columns={'Song':\"Songs_Count\"},inplace=True)\n",
    "song_c=songs_count_df['Songs_Count'].reset_index()\n",
    "song_c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We shall use plotly barchart to view the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~petra.shini/0 or inside your plot.ly account where it is named 'basic-bar'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~petra.shini/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='petra.shini', api_key='2WD1djeDjhtyuH5XDk78')\n",
    "\n",
    "graph = [go.Bar(\n",
    "            x=song_c['Genre'],\n",
    "            y=song_c['Songs_Count']\n",
    "    )]\n",
    "\n",
    "py.iplot(graph, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/song_count.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us see the distribution of artist count per genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Artist_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indie</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>metal</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pop</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rock</td>\n",
       "      <td>1443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Genre  Artist_Count\n",
       "0  country           347\n",
       "1    indie           734\n",
       "2    metal           600\n",
       "3      pop           731\n",
       "4     rock          1443"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_artist_dict ={}\n",
    "artists = df[['Artist','Genre']].groupby(['Genre','Artist']).agg('count')\n",
    "\n",
    "genres=list(df['Genre'].unique())\n",
    "list_genre_artist = artists.index.tolist()\n",
    "genres=sorted(genres)\n",
    "for i in range(5):\n",
    "    genre_artist_dict[genres[i]]=0\n",
    "\n",
    "for tup in list_genre_artist:\n",
    "    genre_artist_dict[tup[0]]+=1\n",
    "\n",
    "\n",
    "genre_artist_dict\n",
    "li =[]\n",
    "for k,v in genre_artist_dict.items():\n",
    "    tup = (k,v)\n",
    "    li.append(tup)\n",
    "\n",
    "artist_count_df = pd.DataFrame(li,columns=['Genre','Artist_Count'])\n",
    "artist_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We shall use plotly barchart to view the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~petra.shini/0 or inside your plot.ly account where it is named 'basic-bar'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~petra.shini/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='petra.shini', api_key='2WD1djeDjhtyuH5XDk78')\n",
    "graph = [go.Bar(\n",
    "            x=artist_count_df['Genre'],\n",
    "            y=artist_count_df['Artist_Count']\n",
    "    )]\n",
    "\n",
    "py.iplot(graph, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/artist_count.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see what are the most important words based on TFIDF feature matrix. We will create separate data frames for each genre use it to create a list of tfidf feature matrix per genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metal = df[df['Genre'] == 'metal']\n",
    "df_pop = df[df['Genre'] == 'pop']\n",
    "df_rock = df[df['Genre'] == 'rock']\n",
    "df_country = df[df['Genre'] == 'country']\n",
    "df_indie = df[df['Genre'] == 'indie']\n",
    "\n",
    "df_list=[df_country,df_indie,df_metal,df_pop,df_rock]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We remove punctuation and tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_wc(text):\n",
    "    trans = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    NoPunc = text.translate(trans)\n",
    "    dataList =  nltk.tokenize.word_tokenize(NoPunc)\n",
    "    return dataList\n",
    "\n",
    "def process_all_wc(df):\n",
    "    for i, row in df.iterrows():\n",
    "        tempList=process_wc(getattr(row,'Lyrics'))\n",
    "        df.set_value(i, 'Lyrics', tempList)\n",
    "    \n",
    "    return df\n",
    "\n",
    "process_df = [process_all_wc(df) for df in df_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a list of TFIDF matrices for each genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_list = []\n",
    "\n",
    "tf_idf_x = sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "for x in process_df:\n",
    "    tempL = []\n",
    "    for y in x['Lyrics']:\n",
    "        x2  = \" \".join(y)\n",
    "        tempL.append(x2)\n",
    "    tf_idf_list.append(tf_idf_x.fit_transform(tempL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a list of dictionary of the words which are important in every genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_list = []\n",
    "\n",
    "for x in tf_idf_list:\n",
    "    w_dict = OrderedDict()\n",
    "    scores = zip(tf_idf_x.get_feature_names(),np.asarray(x.sum(axis=0)).ravel())\n",
    "    scores_sort = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    i=0\n",
    "    for y in scores_sort:\n",
    "        if i<30:\n",
    "            w_dict[y[0]] = y[1]\n",
    "            i+=1\n",
    "    w_list.append(w_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the WordCloud library, here are a few important words seen per genre. Here is an example of Country genre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_list=[]\n",
    "for genre_dict in w_list:\n",
    "    str_temp=\"\"\n",
    "    for key in genre_dict.keys():\n",
    "        str_temp=str_temp+\" \"+key\n",
    "    wc = WordCloud(width=800,height=400).generate(str_temp)\n",
    "    wc_list.append(wc.to_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_list[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Processing\n",
    "\n",
    "Let's process data lyrics for Word2Vec and TFIDF to lemmatize and remove punctuations. We will iterate throguh lyrics of each song and remove the punctuations and stem the words using WordNetLemmatizer.Word2vec needs a a lemmatized corpus of lyrics data that we need to feed in to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize,sent_tokenize\n",
    "def process(text, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "    \n",
    "    lowers=text.lower()\n",
    "    break_hyphen_apos = lowers.replace(\"'s\",\"\").replace(\"'\",\"\")\n",
    "    no_punctuation = break_hyphen_apos\n",
    "    for sym in string.punctuation:\n",
    "        no_punctuation = no_punctuation.replace(sym,\" \")\n",
    "    tokens= nltk.word_tokenize(no_punctuation)\n",
    "    lem_tokens =[]\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            lem_tokens.append(str(lemmatizer.lemmatize(w)))\n",
    "        except:\n",
    "            pass\n",
    "    return lem_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_all(df, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):    \n",
    "    df_out =df.copy(deep=True)\n",
    "    for i,row in df_out.iterrows():\n",
    "        df_out.at[i,'Lyrics'] = process(row['Lyrics'],lemmatizer)\n",
    "    return df_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Lyrics\n",
      "0  [i, never, wrote, a, love, song, that, didn, t...\n",
      "1  [our, little, boy, is, four, year, old, and, q...\n",
      "2  [too, much, of, anything, can, make, you, sick...\n",
      "3  [look, around, help, me, out, breaking, up, br...\n",
      "4  [why, can, t, you, just, believe, in, me, not,...\n"
     ]
    }
   ],
   "source": [
    "processed_lyrics = process_all(pd.DataFrame(data['Lyrics']))\n",
    "processed_lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>[we, are, the, industry, people, with, this, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11292</th>\n",
       "      <td>[boom, semi, automatic, pulse, psyched, up, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11293</th>\n",
       "      <td>[and, if, i, wa, wrong, again, what, else, hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11294</th>\n",
       "      <td>[you, should, listen, very, well, i, m, about,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11295</th>\n",
       "      <td>[i, believe, i, believe, i, believe, i, believ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Lyrics\n",
       "11291  [we, are, the, industry, people, with, this, d...\n",
       "11292  [boom, semi, automatic, pulse, psyched, up, fo...\n",
       "11293  [and, if, i, wa, wrong, again, what, else, hav...\n",
       "11294  [you, should, listen, very, well, i, m, about,...\n",
       "11295  [i, believe, i, believe, i, believe, i, believ..."
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_lyrics.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Song</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Genre</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>Zeromancer</td>\n",
       "      <td>Industrypeople</td>\n",
       "      <td>We are the Industry people  With this death ki...</td>\n",
       "      <td>metal</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11292</th>\n",
       "      <td>Zeromancer</td>\n",
       "      <td>Raising Hell</td>\n",
       "      <td>Boom Semi automatic pulse Psyched up for the n...</td>\n",
       "      <td>metal</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11293</th>\n",
       "      <td>Zornik</td>\n",
       "      <td>Once Again</td>\n",
       "      <td>And if I was wrong again What else have you ke...</td>\n",
       "      <td>rock</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11294</th>\n",
       "      <td>Zornik</td>\n",
       "      <td>This Song Is Just For You</td>\n",
       "      <td>You should listen very well I m about to lose ...</td>\n",
       "      <td>rock</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11295</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Honestly  Album Version</td>\n",
       "      <td>I believe I believe I believe I believe the lo...</td>\n",
       "      <td>indie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Artist                       Song  \\\n",
       "11291  Zeromancer             Industrypeople   \n",
       "11292  Zeromancer               Raising Hell   \n",
       "11293      Zornik                 Once Again   \n",
       "11294      Zornik  This Song Is Just For You   \n",
       "11295        Zwan   Honestly  Album Version    \n",
       "\n",
       "                                                  Lyrics  Genre  labels  \n",
       "11291  We are the Industry people  With this death ki...  metal       4  \n",
       "11292  Boom Semi automatic pulse Psyched up for the n...  metal       4  \n",
       "11293  And if I was wrong again What else have you ke...   rock       3  \n",
       "11294  You should listen very well I m about to lose ...   rock       3  \n",
       "11295  I believe I believe I believe I believe the lo...  indie       0  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick sanity check on the data and processed tokenized lyric\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rare_words(processed_lyrics):\n",
    "    all_tokens=[]\n",
    "    for i,row in processed_lyrics.iterrows():\n",
    "        all_tokens += row['Lyrics']\n",
    "    count = Counter(all_tokens)\n",
    "    count_dict = dict(count)\n",
    "    return sorted([k for k in count_dict if count_dict[k]<=1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features(processed_lyrics,rare_words):\n",
    "    lyrics_text =list(processed_lyrics['Lyrics'].apply(lambda x: ' '.join(w for w in x)))\n",
    "    words_to_omit = [str(word) for word in rare_words + nltk.corpus.stopwords.words('english')]\n",
    "    \n",
    "    tfidf = sklearn.feature_extraction.text.TfidfVectorizer(stop_words=words_to_omit)\n",
    "#     print(lyrics_text[:3])\n",
    "    feature_matrix = tfidf.fit_transform(lyrics_text)\n",
    "    return (tfidf, feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF feature matrix with more processing\n",
    "We will first use the processed lyrics for tfidf to create a sparse feature matrix and also pass in the rare_words to be omitted. We will go on to create a dense matrix so that we can concatenate the features with Word2Vec features for our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_words = get_rare_words(processed_lyrics)\n",
    "(tfidf, feature_matrix_tfidf) = create_features(processed_lyrics, rare_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11296, 18678)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_feat_dense = feature_matrix_tfidf.todense() #making a dense matrix to concatenate to full feature matrix with w2v features\n",
    "tfidf_feat_dense.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec feature extraction\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is a class of neural network model developed to extract word vectors that are useful in NLP tasks. The neural network takes in a large corpus of text, analyzes it, and for each word in the vocabulary, generates a vector of numbers that represent that word. Those vectors are useful to signify important information about the meaning of the word in relation to the context in which it appears."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source:https://www.tensorflow.org/images/softmax-nplm.png]<img src=\"img/softmax-nplm.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Corpus creation from processed lyrics.A corpus should be list of lists each list containing tokenized lyric sentences.\n",
    "s=[]\n",
    "for i in range(len(processed_lyrics.Lyrics)): \n",
    "    m =(processed_lyrics.iloc[i].astype(list))\n",
    "    f=' '.join(m[0])\n",
    "    t=f.split()\n",
    "    s.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features=150\n",
    "downsampling = 1e-3\n",
    "min_wordcount=3\n",
    "num_workers=multiprocessing.cpu_count()\n",
    "seed=1\n",
    "context_size=7\n",
    "corpus=s \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17270826, 24913650)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model = gensim.models.Word2Vec(sg=1,seed=seed,size=num_features,min_count=min_wordcount,window=context_size,sample=downsampling)\n",
    "w2v_model.build_vocab(corpus)\n",
    "w2v_model.train(corpus, total_examples=w2v_model.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code to save the model to the local disk\n",
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")\n",
    "w2v_model.save(os.path.join(\"trained\", \"w2v_model.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visual Representation of Vocabulary trained with Word2Vec Using Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use t-SNE to build our vizualization. t-SNE is a tool used to vizualize high dimensional data which uses non-linear dimensionality reduction. We will have a 2d matrix at the end of training and can easily plot the data, which is handy with high dimension word vectors.\n",
    "\n",
    "In the visualization below you can see that the words like \"wander\" and \"escape\" appear together and \"hollow\",\"darkness\",\"mercy\",\"pain\" appear together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = sklearn.manifold.TSNE(n_components=2, perplexity=30.0, early_exaggeration=12.0,learning_rate=200.0, n_iter=250,verbose=0, random_state=seed,angle=0.5)\n",
    "w2v_mat = w2v_model.wv.vectors\n",
    "w2v_mat_2d = tsne.fit_transform(w2v_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13282"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result =[]\n",
    "for word in w2v_model.wv.vocab:\n",
    "    rec=(word,w2v_mat_2d[w2v_model.wv.vocab[word].index])\n",
    "    result.append(rec)\n",
    "\n",
    "points=[]\n",
    "for word,pts in result:\n",
    "    rec=(word,pts[0],pts[1])\n",
    "    points.append(rec)\n",
    "\n",
    "plo_df = pd.DataFrame(points,columns=[\"word\", \"x\", \"y\"])\n",
    "\n",
    "len(plo_df.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0096932621672749519,\n",
       " 0.011893876828253269,\n",
       " 0.0047191604971885681,\n",
       " 0.0061029852367937565,\n",
       " 0.0064467703923583031,\n",
       " 0.0023108129389584064,\n",
       " 0.0099462596699595451,\n",
       " 0.0086470842361450195,\n",
       " 0.007257404737174511,\n",
       " 0.0043367496691644192]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_x = list(plo_df.x)  #Slicing the data points to have a smaller representation of the vocab\n",
    "li_y = list(plo_df.y)\n",
    "li_word = list(plo_df.word)\n",
    "li_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~petra.shini/0 or inside your plot.ly account where it is named 'basic-bar'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~petra.shini/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='petra.shini', api_key='2WD1djeDjhtyuH5XDk78')\n",
    "\n",
    "data = [go.Scatter(\n",
    "            x=li_x[:1000],\n",
    "            y=li_y[:1000],\n",
    "            mode = 'markers+text',\n",
    "            name='Markers and Text',\n",
    "            text=li_word[:1000]\n",
    "    )]\n",
    "\n",
    "py.iplot(data, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/w2v.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will prepare the feature matrix by following the steps below:\n",
    "1. We will first prepare a list of lyrics\n",
    "2. We will prepare a list of vectors for each word seen in each lyric. So this will be a list of lists where each list is a list of vector for each word in each lyric.\n",
    "3. We will prepare a vector from these vectors for each lyric.We normalize this by length of the w2v feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_list=[]\n",
    "for i in range(len(processed_lyrics['Lyrics'])):\n",
    "    token_list.append(processed_lyrics['Lyrics'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13282"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_vocab=w2v_model.wv.vocab #Vocabulary of our model : Different words seen and learned (13282)\n",
    "wv_vocab=set(wv_vocab)\n",
    "wv_vocab=list(wv_vocab)\n",
    "len(wv_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_token_list=[] \n",
    "for token in token_list: \n",
    "    vc_list=[] \n",
    "    for word in token:\n",
    "        if (word in wv_vocab):\n",
    "            vc_list.append(w2v_model.wv[word])\n",
    "    word2vec_token_list.append(vc_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_arr=[]\n",
    "for i in range (len(word2vec_token_list)):\n",
    "    word_vector_arr.append(np.sum(word2vec_token_list[i], axis=0)/len(word2vec_token_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11296"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vector_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will prepare a dataframe of word vectors for each song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns=[\"w2v_\"+str(i) for i in range(1,151)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in range (len(word_vector_arr)):\n",
    "    try:\n",
    "        if(type(word_vector_arr[x])==float):\n",
    "            word_vector_arr[x]=[0]*150\n",
    "        word_vector_arr[x]=word_vector_arr[x].tolist()\n",
    "    except:\n",
    "         print(\"Exception with the record %d\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range (len(word_vector_arr)):\n",
    "    try:\n",
    "        if(type(word_vector_arr[x])==float):\n",
    "            word_vector_arr[x]=[0]*150\n",
    "    except:\n",
    "        print(\"Exception with the record %d\",i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w2v_1</th>\n",
       "      <th>w2v_2</th>\n",
       "      <th>w2v_3</th>\n",
       "      <th>w2v_4</th>\n",
       "      <th>w2v_5</th>\n",
       "      <th>w2v_6</th>\n",
       "      <th>w2v_7</th>\n",
       "      <th>w2v_8</th>\n",
       "      <th>w2v_9</th>\n",
       "      <th>w2v_10</th>\n",
       "      <th>...</th>\n",
       "      <th>w2v_141</th>\n",
       "      <th>w2v_142</th>\n",
       "      <th>w2v_143</th>\n",
       "      <th>w2v_144</th>\n",
       "      <th>w2v_145</th>\n",
       "      <th>w2v_146</th>\n",
       "      <th>w2v_147</th>\n",
       "      <th>w2v_148</th>\n",
       "      <th>w2v_149</th>\n",
       "      <th>w2v_150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.091226</td>\n",
       "      <td>0.043216</td>\n",
       "      <td>0.021632</td>\n",
       "      <td>-0.266216</td>\n",
       "      <td>-0.012158</td>\n",
       "      <td>0.068803</td>\n",
       "      <td>0.241478</td>\n",
       "      <td>0.132305</td>\n",
       "      <td>-0.006555</td>\n",
       "      <td>-0.026983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027611</td>\n",
       "      <td>0.084050</td>\n",
       "      <td>-0.106993</td>\n",
       "      <td>0.055456</td>\n",
       "      <td>0.009545</td>\n",
       "      <td>0.081817</td>\n",
       "      <td>0.033357</td>\n",
       "      <td>-0.023373</td>\n",
       "      <td>-0.120461</td>\n",
       "      <td>0.052595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.077191</td>\n",
       "      <td>-0.001188</td>\n",
       "      <td>-0.080999</td>\n",
       "      <td>-0.227991</td>\n",
       "      <td>0.078716</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.231695</td>\n",
       "      <td>0.161938</td>\n",
       "      <td>-0.017654</td>\n",
       "      <td>0.102774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.051436</td>\n",
       "      <td>-0.000795</td>\n",
       "      <td>0.139114</td>\n",
       "      <td>0.016408</td>\n",
       "      <td>0.082564</td>\n",
       "      <td>0.094837</td>\n",
       "      <td>0.017562</td>\n",
       "      <td>-0.003645</td>\n",
       "      <td>-0.017547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021176</td>\n",
       "      <td>0.035554</td>\n",
       "      <td>-0.013146</td>\n",
       "      <td>-0.316167</td>\n",
       "      <td>-0.126101</td>\n",
       "      <td>-0.029613</td>\n",
       "      <td>0.191664</td>\n",
       "      <td>0.192894</td>\n",
       "      <td>0.062167</td>\n",
       "      <td>0.027285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018484</td>\n",
       "      <td>0.127104</td>\n",
       "      <td>0.058654</td>\n",
       "      <td>0.116177</td>\n",
       "      <td>-0.063940</td>\n",
       "      <td>0.056207</td>\n",
       "      <td>-0.051344</td>\n",
       "      <td>0.017871</td>\n",
       "      <td>-0.015343</td>\n",
       "      <td>0.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.050631</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>-0.012037</td>\n",
       "      <td>-0.234254</td>\n",
       "      <td>0.063036</td>\n",
       "      <td>0.046872</td>\n",
       "      <td>0.276216</td>\n",
       "      <td>0.130091</td>\n",
       "      <td>0.006562</td>\n",
       "      <td>0.023117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027318</td>\n",
       "      <td>0.132657</td>\n",
       "      <td>-0.043840</td>\n",
       "      <td>0.100148</td>\n",
       "      <td>-0.110978</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.052179</td>\n",
       "      <td>0.033272</td>\n",
       "      <td>-0.055871</td>\n",
       "      <td>-0.021016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051861</td>\n",
       "      <td>0.040565</td>\n",
       "      <td>0.023340</td>\n",
       "      <td>-0.326930</td>\n",
       "      <td>-0.013760</td>\n",
       "      <td>0.065183</td>\n",
       "      <td>0.236713</td>\n",
       "      <td>0.107732</td>\n",
       "      <td>-0.034442</td>\n",
       "      <td>0.020876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040938</td>\n",
       "      <td>0.150314</td>\n",
       "      <td>-0.046189</td>\n",
       "      <td>0.067806</td>\n",
       "      <td>-0.052085</td>\n",
       "      <td>0.137402</td>\n",
       "      <td>0.007252</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>-0.084334</td>\n",
       "      <td>0.044543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      w2v_1     w2v_2     w2v_3     w2v_4     w2v_5     w2v_6     w2v_7  \\\n",
       "0  0.091226  0.043216  0.021632 -0.266216 -0.012158  0.068803  0.241478   \n",
       "1  0.077191 -0.001188 -0.080999 -0.227991  0.078716  0.008749  0.231695   \n",
       "2  0.021176  0.035554 -0.013146 -0.316167 -0.126101 -0.029613  0.191664   \n",
       "3 -0.050631  0.003183 -0.012037 -0.234254  0.063036  0.046872  0.276216   \n",
       "4  0.051861  0.040565  0.023340 -0.326930 -0.013760  0.065183  0.236713   \n",
       "\n",
       "      w2v_8     w2v_9    w2v_10    ...      w2v_141   w2v_142   w2v_143  \\\n",
       "0  0.132305 -0.006555 -0.026983    ...    -0.027611  0.084050 -0.106993   \n",
       "1  0.161938 -0.017654  0.102774    ...     0.001886  0.051436 -0.000795   \n",
       "2  0.192894  0.062167  0.027285    ...    -0.018484  0.127104  0.058654   \n",
       "3  0.130091  0.006562  0.023117    ...    -0.027318  0.132657 -0.043840   \n",
       "4  0.107732 -0.034442  0.020876    ...    -0.040938  0.150314 -0.046189   \n",
       "\n",
       "    w2v_144   w2v_145   w2v_146   w2v_147   w2v_148   w2v_149   w2v_150  \n",
       "0  0.055456  0.009545  0.081817  0.033357 -0.023373 -0.120461  0.052595  \n",
       "1  0.139114  0.016408  0.082564  0.094837  0.017562 -0.003645 -0.017547  \n",
       "2  0.116177 -0.063940  0.056207 -0.051344  0.017871 -0.015343  0.057000  \n",
       "3  0.100148 -0.110978  0.004001  0.052179  0.033272 -0.055871 -0.021016  \n",
       "4  0.067806 -0.052085  0.137402  0.007252 -0.002269 -0.084334  0.044543  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_features=pd.DataFrame(word_vector_arr,columns=columns)\n",
    "w2v_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating feature matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate the TFIDF feature matrix and the Word2Vec feature matrix to create a new robust model. We convert the matrices into dataframes and concatenate the two dataframes. We shall use this trained dataframe to perform classification of genres using different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w2v_1</th>\n",
       "      <th>w2v_2</th>\n",
       "      <th>w2v_3</th>\n",
       "      <th>w2v_4</th>\n",
       "      <th>w2v_5</th>\n",
       "      <th>w2v_6</th>\n",
       "      <th>w2v_7</th>\n",
       "      <th>w2v_8</th>\n",
       "      <th>w2v_9</th>\n",
       "      <th>w2v_10</th>\n",
       "      <th>...</th>\n",
       "      <th>18668</th>\n",
       "      <th>18669</th>\n",
       "      <th>18670</th>\n",
       "      <th>18671</th>\n",
       "      <th>18672</th>\n",
       "      <th>18673</th>\n",
       "      <th>18674</th>\n",
       "      <th>18675</th>\n",
       "      <th>18676</th>\n",
       "      <th>18677</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.091226</td>\n",
       "      <td>0.043216</td>\n",
       "      <td>0.021632</td>\n",
       "      <td>-0.266216</td>\n",
       "      <td>-0.012158</td>\n",
       "      <td>0.068803</td>\n",
       "      <td>0.241478</td>\n",
       "      <td>0.132305</td>\n",
       "      <td>-0.006555</td>\n",
       "      <td>-0.026983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.077191</td>\n",
       "      <td>-0.001188</td>\n",
       "      <td>-0.080999</td>\n",
       "      <td>-0.227991</td>\n",
       "      <td>0.078716</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.231695</td>\n",
       "      <td>0.161938</td>\n",
       "      <td>-0.017654</td>\n",
       "      <td>0.102774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021176</td>\n",
       "      <td>0.035554</td>\n",
       "      <td>-0.013146</td>\n",
       "      <td>-0.316167</td>\n",
       "      <td>-0.126101</td>\n",
       "      <td>-0.029613</td>\n",
       "      <td>0.191664</td>\n",
       "      <td>0.192894</td>\n",
       "      <td>0.062167</td>\n",
       "      <td>0.027285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.050631</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>-0.012037</td>\n",
       "      <td>-0.234254</td>\n",
       "      <td>0.063036</td>\n",
       "      <td>0.046872</td>\n",
       "      <td>0.276216</td>\n",
       "      <td>0.130091</td>\n",
       "      <td>0.006562</td>\n",
       "      <td>0.023117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051861</td>\n",
       "      <td>0.040565</td>\n",
       "      <td>0.023340</td>\n",
       "      <td>-0.326930</td>\n",
       "      <td>-0.013760</td>\n",
       "      <td>0.065183</td>\n",
       "      <td>0.236713</td>\n",
       "      <td>0.107732</td>\n",
       "      <td>-0.034442</td>\n",
       "      <td>0.020876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  18828 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      w2v_1     w2v_2     w2v_3     w2v_4     w2v_5     w2v_6     w2v_7  \\\n",
       "0  0.091226  0.043216  0.021632 -0.266216 -0.012158  0.068803  0.241478   \n",
       "1  0.077191 -0.001188 -0.080999 -0.227991  0.078716  0.008749  0.231695   \n",
       "2  0.021176  0.035554 -0.013146 -0.316167 -0.126101 -0.029613  0.191664   \n",
       "3 -0.050631  0.003183 -0.012037 -0.234254  0.063036  0.046872  0.276216   \n",
       "4  0.051861  0.040565  0.023340 -0.326930 -0.013760  0.065183  0.236713   \n",
       "\n",
       "      w2v_8     w2v_9    w2v_10  ...    18668  18669  18670  18671  18672  \\\n",
       "0  0.132305 -0.006555 -0.026983  ...      0.0    0.0    0.0    0.0    0.0   \n",
       "1  0.161938 -0.017654  0.102774  ...      0.0    0.0    0.0    0.0    0.0   \n",
       "2  0.192894  0.062167  0.027285  ...      0.0    0.0    0.0    0.0    0.0   \n",
       "3  0.130091  0.006562  0.023117  ...      0.0    0.0    0.0    0.0    0.0   \n",
       "4  0.107732 -0.034442  0.020876  ...      0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   18673  18674  18675  18676  18677  \n",
       "0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 18828 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features = pd.DataFrame(tfidf_feat_dense)\n",
    "full_df = pd.concat([w2v_features,tfidf_features ],axis=1)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into train and test. 80 % train data and 20 % test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test,train_y,test_y = train_test_split(full_df,lab,train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using various classifiers to classify the genres and calculating accuracy scores \n",
    "\n",
    "The different classifiers we use are :\n",
    "\n",
    "1. Dummy Classifier\n",
    "2. SVM\n",
    "3. K-Nearest Neighbour Classifier\n",
    "4. Neural Network MLP Classifier\n",
    "5. Random Forest Classifier\n",
    "6. Adaboost Classifier\n",
    "7. Logistic Regression\n",
    "8. Gaussian Naive Bayes\n",
    "\n",
    "The number below each cell represents the mean accuracy on the given test data and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23141592920353982"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = DummyClassifier()\n",
    "d.fit(train,train_y)\n",
    "pred = d.predict(test)\n",
    "dummy_class_acc_score=d.score(test,test_y)\n",
    "dummy_class_acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM : LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69026548672566368"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SV = LinearSVC(max_iter=10000)\n",
    "SV.fit(train,train_y)\n",
    "pred = SV.predict(test)\n",
    "svm_acc_score=SV.score(test,test_y)\n",
    "svm_acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43141592920353983"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(train,train_y) \n",
    "pred = neigh.predict(test)\n",
    "knn_acc_score=neigh.score(test,test_y)\n",
    "knn_acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neutral Network : MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71017699115044253"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = MLPClassifier()\n",
    "nn.fit(train,train_y)\n",
    "pred = nn.predict(test)\n",
    "nn_acc_score=nn.score(test,test_y)\n",
    "nn_acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67654867256637163"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(train,train_y)\n",
    "pred = RF.predict(test)\n",
    "rf_acc_score=RF.score(test,test_y)\n",
    "rf_acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47522123893805307"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad = AdaBoostClassifier()\n",
    "ad.fit(train,train_y)\n",
    "pred = ad.predict(test)\n",
    "ad_acc_score=ad.score(test,test_y)\n",
    "ad_acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60663716814159296"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg = logreg.fit(train, train_y)\n",
    "pred=logreg.predict(test)\n",
    "lg_acc_score=logreg.score(test,test_y)\n",
    "lg_acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58362831858407083"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = GaussianNB()\n",
    "NB.fit(train,train_y)\n",
    "pred = NB.predict(test)\n",
    "nb_acc_score=NB.score(test,test_y)\n",
    "nb_acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see MLP Classifier, SVM, Random Forest and Logistic Regression are classifying the genres with around 60-70% accuracy. MLP classifier performs the best among all with 71% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a list of Classifiers and Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list =[\"Dummy\",\"Support Vector Machine\",\"K-Nearest Neighbours\",\"MLP classifier\",\"Random Forest\",\"Ada Boost\",\"Logistic Regression\",\"Gaussian Naive Bayes\"]\n",
    "accuracy_list=[dummy_class_acc_score,svm_acc_score,knn_acc_score,nn_acc_score,rf_acc_score,ad_acc_score,lg_acc_score,nb_acc_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~petra.shini/0 or inside your plot.ly account where it is named 'basic-bar'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~petra.shini/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='petra.shini', api_key='2WD1djeDjhtyuH5XDk78')\n",
    "graph = [go.Bar(\n",
    "            x=classifier_list,\n",
    "            y=accuracy_list\n",
    "    )]\n",
    "\n",
    "py.iplot(graph, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/accuracy.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/sarthak18593/Music-Genre-Classification-by-Lyric-Analysis\n",
    "\n",
    "https://github.com/llSourcell/word_vectors_game_of_thrones-LIVE/blob/master/Thrones2Vec.ipynb\n",
    "\n",
    "\n",
    "https://www.tensorflow.org/tutorials/word2vec\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/using-word2vec-for-music-recommendations-bb9649ac2484\n",
    "\n",
    "Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and Paul Lamere. \n",
    "The Million Song Dataset. In Proceedings of the 12th International Society\n",
    "for Music Information Retrieval Conference (ISMIR 2011), 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Looking at the accuracies, we're able to see that while _lyrics alone_ are not sufficient to successfully classify songs into genres, this is a promising start in identifying newer features for songs that complements existing features offered by commercial music recommendation systems like Spotify and Last.fm.\n",
    "\n",
    "By identifying key \"topics\" or words in genres that define what the genre is all about, we're able to identify the genre any given song could belong to, with a good deal of certainty.\n",
    "\n",
    "# Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
